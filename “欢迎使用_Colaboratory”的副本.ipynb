{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuruicai/common/blob/master/%E2%80%9C%E6%AC%A2%E8%BF%8E%E4%BD%BF%E7%94%A8_Colaboratory%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# longChain"
      ],
      "metadata": {
        "id": "18f45l9TWpDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "EoIFr0LQf4KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken"
      ],
      "metadata": {
        "id": "6ODAPvEI3Qv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain\n"
      ],
      "metadata": {
        "id": "Mtx9CjJsfmlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-search-results"
      ],
      "metadata": {
        "id": "y3OH6WicimKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'sk-。。。'\n"
      ],
      "metadata": {
        "id": "h4dxVGN7fFrD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9,model_name=\"text-davinci-003\",max_tokens=1024)\n",
        "llm(\"langchain 是什么？\")"
      ],
      "metadata": {
        "id": "CjWb5cOofHUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "google serpapi"
      ],
      "metadata": {
        "id": "ibVqcUaJiEJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'sk-。。。'\n",
        "os.environ[\"SERPAPI_API_KEY\"] = '。。'\n"
      ],
      "metadata": {
        "id": "e9TmWDEgiNwq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "搜索代码"
      ],
      "metadata": {
        "id": "sEy_acxMiW9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu"
      ],
      "metadata": {
        "id": "OHZoonPn3exK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Templates：管理LLMs的提示\n",
        "通常，在应用程序中使用LLM时，不会直接将用户输入直接发送到LLM。相反，你可能会获取用户输入并构造一个提示，然后将提示发送到LLM中。\n",
        "\n",
        "首先定义提示模板："
      ],
      "metadata": {
        "id": "FdtvXTG23v9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")\n",
        "\n",
        "print(prompt.format(product=\"colorful socks\"))\n"
      ],
      "metadata": {
        "id": "UuK8unuE3wxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "将LLMs和Prompts结合在多步骤工作流中\n",
        "在LangChain中，一个链由链接组成，这些链接可以是LLM、Prompt Template或其他链。\n",
        "\n",
        "LLMChain是最核心的链类型，它由Prompt Template和LLM组成。\n",
        "\n",
        "扩展上一个例子，我们可以构建一个LLMChain，该链接受用户输入，使用Prompt Template格式化它，然后将格式化的响应传递给LLM。"
      ],
      "metadata": {
        "id": "9DDB9aCW4IEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "efjVmtC64IvV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "创建一个非常简单的链，该链将获取用户输入，使用Prompt Template对其进行格式化，然后将其发送到LLM"
      ],
      "metadata": {
        "id": "obTkb6nP4ewL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n"
      ],
      "metadata": {
        "id": "HsRAHGOL4g6i"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "运行该链，只需指定产品即可"
      ],
      "metadata": {
        "id": "Z6xPJbrd4ji9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"colorful socks\")\n"
      ],
      "metadata": {
        "id": "Tb6yiM4C4pIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agents：根据用户输入动态调用Chains\n",
        "已经看到的链都是按照预定顺序运行的。Agents不再如此：它们使用LLM确定要采取的动作及其顺序。一个动作可以是使用工具并观察其输出，或者返回给用户。\n",
        "如果正确使用Agents，它们可以非常强大\n",
        "\n",
        "执行特定任务的功能。这可以是类似Google搜索、数据库查找、Python REPL、其他链的东西。工具的接口目前是期望有一个字符串作为输入，输出一个字符串的函数。\n",
        "\n",
        "安装SerpAPI Python包。\n"
      ],
      "metadata": {
        "id": "JSBtXJ7O4wLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-search-results"
      ],
      "metadata": {
        "id": "naub-rvj4xB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# 首先，加载我们要用来控制代理的语言模型。\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# 接下来，加载一些要使用的工具。请注意，`llm-math`工具使用LLM，因此我们需要将其传递给它。\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "\n",
        "# 最后，使用工具、语言模型和我们想要使用的代理类型来初始化一个代理。\n",
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "\n",
        "# 现在让我们测试一下！\n",
        "agent.run(\"詹姆斯和韦德的出生地是哪里，他们两个年龄相加是多少?\")\n"
      ],
      "metadata": {
        "id": "DGoh7Dy4idDf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "20af896d-e434-44c7-f2f2-f6ba1b167bf1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out where they were born and their ages\n",
            "Action: Search\n",
            "Action Input: \"LeBron James and Dwyane Wade birthplace and age\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mDwyane Tyrone Wade Jr is an American former professional basketball player. Wade spent the majority of his 16-year career playing for the Miami Heat of the ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find out their exact birthplaces and ages\n",
            "Action: Search\n",
            "Action Input: \"LeBron James and Dwyane Wade birthplace and age exact\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mDwyane Tyrone Wade Jr is an American former professional basketball player. Wade spent the majority of his 16-year career playing for the Miami Heat of the ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the exact birthplaces and ages\n",
            "Final Answer: LeBron James was born in Akron, Ohio on December 30, 1984 and Dwyane Wade was born in Chicago, Illinois on January 17, 1982. The sum of their ages is 66.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LeBron James was born in Akron, Ohio on December 30, 1984 and Dwyane Wade was born in Chicago, Illinois on January 17, 1982. The sum of their ages is 66.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os; \n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import AgentType\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-。。。。。\"\n",
        "\n",
        "text = \"What would be a good company name a company that makes colorful socks?\"\n",
        "\n",
        "# 加载 OpenAI 模型\n",
        "llm = OpenAI(temperature=0,max_tokens=2048)\n",
        "\n",
        "print(llm(text)) # 返回 Socktastic!\n",
        "\n",
        "text = \"what is the results of 5+6?\"\n",
        "print(llm(text)) # 返回 11\n",
        "text = \"what is the results of 55+66?\"\n",
        "print(llm(text)) # 返回 121\n",
        "text = \"what is the results of 55555+66666?\"\n",
        "print(llm(text)) # 返回 122221\n",
        "text = \"what is the results of 512311+89749878?\"\n",
        "print(llm(text)) # 返回 89,876,189，终于错了...\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")\n",
        "\n",
        "print(prompt.format(product=\"colorful socks\")) # 返回 What is a good name for a company that makes colorful socks?\n",
        "text = prompt.format(product=\"colorful socks\")\n",
        "print(llm(text)) # 返回 Socktastic！\n",
        "text = prompt.format(product=\"chocolates\")\n",
        "print(llm(text)) # 返回 ChocoDelightz！"
      ],
      "metadata": {
        "id": "M7TbdDgkGchT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}